{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T17:15:08.494914Z",
     "iopub.status.busy": "2023-11-15T17:15:08.494828Z",
     "iopub.status.idle": "2023-11-15T17:15:09.282972Z",
     "shell.execute_reply": "2023-11-15T17:15:09.282696Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate multiple spiral trajectories\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal.windows import gaussian as gausswin\n",
    "\n",
    "im_size = 64\n",
    "spokelength = im_size * 2\n",
    "ntrajs = 8\n",
    "\n",
    "# equally sample high frequency and low frequency\n",
    "theta = gausswin(spokelength*2, std=im_size)[spokelength:]\n",
    "theta = np.cumsum(theta)\n",
    "theta = theta / max(theta) * 4*np.pi    # range of theta determines number of circles: 2*pi forms one circle\n",
    "\n",
    "# spiral curve with radius following gaussian density\n",
    "radius = np.linspace(0, np.pi, len(theta))  # range of radius determins how far lines can go\n",
    "k0 = radius * np.exp(1j * theta) # a single spiral\n",
    "\n",
    "ktrajs = []\n",
    "# generate multiple spirals with different angles\n",
    "cirp = 2j*np.pi * np.arange(im_size)/im_size\n",
    "for i in range(ntrajs):\n",
    "    itlvp = cirp[range(i, im_size, im_size//ntrajs)]\n",
    "    ktraj = np.matmul(k0.T[:,np.newaxis], np.exp(itlvp[np.newaxis,:]))\n",
    "    # convert k-space trajectory to tensor\n",
    "    kx, ky = ktraj.real, ktraj.imag\n",
    "    ktraj = np.stack((ky.flatten(), kx.flatten()), axis=0)\n",
    "    ktraj = torch.from_numpy(ktraj)\n",
    "    ktrajs.append(ktraj)\n",
    "\n",
    "# plot kspace trajectory\n",
    "for i in range(ntrajs):\n",
    "    plt.plot(kx[:, i], ky[:, i])\n",
    "plt.axis('equal')\n",
    "plt.title('kspace trajectory')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T17:15:09.295925Z",
     "iopub.status.busy": "2023-11-15T17:15:09.295831Z",
     "iopub.status.idle": "2023-11-15T17:15:09.322333Z",
     "shell.execute_reply": "2023-11-15T17:15:09.322090Z"
    }
   },
   "outputs": [],
   "source": [
    "# from trajectory, we can form a binary spiral mask, aims for data consistency\n",
    "masks = []\n",
    "for ktraj in ktrajs:\n",
    "    kx, ky = ktraj[0], ktraj[1]\n",
    "    xs, ys = kx / np.pi, ky / np.pi\n",
    "    xs, ys = (xs + 1) / 2 * (im_size-1), (ys + 1) / 2 * (im_size-1)\n",
    "\n",
    "    xs, ys = xs.tolist(), ys.tolist()\n",
    "    mask = torch.zeros([im_size, im_size])\n",
    "    for x, y in zip(xs, ys):\n",
    "        x, y = round(x), round(y)\n",
    "        mask[x, y] = 1.\n",
    "    masks.append(mask)\n",
    "masks = torch.stack(masks)[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T17:15:09.323385Z",
     "iopub.status.busy": "2023-11-15T17:15:09.323304Z",
     "iopub.status.idle": "2023-11-15T17:15:09.325057Z",
     "shell.execute_reply": "2023-11-15T17:15:09.324902Z"
    }
   },
   "outputs": [],
   "source": [
    "# define some utility function\n",
    "from torch.fft import *\n",
    "\n",
    "def ifft2c(k):\n",
    "    return ifftshift(ifft2(fftshift(k)))\n",
    "\n",
    "def fft2c(x):\n",
    "    return fftshift(fft2(ifftshift(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T17:15:09.326054Z",
     "iopub.status.busy": "2023-11-15T17:15:09.325996Z",
     "iopub.status.idle": "2023-11-15T17:15:09.360947Z",
     "shell.execute_reply": "2023-11-15T17:15:09.360784Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup seed\n",
    "import torch\n",
    "import random\n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "setup_seed(12345)\n",
    "# set num threads\n",
    "torch.set_num_threads(8)    # too many threads may kill python kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T17:15:09.361886Z",
     "iopub.status.busy": "2023-11-15T17:15:09.361804Z",
     "iopub.status.idle": "2023-11-15T17:15:09.435743Z",
     "shell.execute_reply": "2023-11-15T17:15:09.435493Z"
    }
   },
   "outputs": [],
   "source": [
    "# define dataset\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torchkbnufft as tkbn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class dataset(Dataset):\n",
    "    \"\"\"\n",
    "    :param ktraj - run cell tagged ktraj to obtain spiral trajectory\n",
    "    :return complexType zero-filled image zf and original image xf\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path, ktrajs, im_size, nimgs):\n",
    "        # load all data into memory\n",
    "        self.nimgs = nimgs\n",
    "        self.ktrajs = torch.stack(ktrajs).cuda()\n",
    "        names = set([os.path.splitext(name)[0] for name in os.listdir(data_path)])\n",
    "        self.data_dict = {}\n",
    "        for name in names:\n",
    "            self.data_dict[name] = {}\n",
    "            data = torch.from_numpy(np.load(os.path.join(data_path, f'{name}.npy')))\n",
    "            with open(os.path.join(data_path, f'{name}.pkl'), 'rb') as f:\n",
    "                offsets = pickle.load(f)\n",
    "            # sort out M0 images and functional images\n",
    "            m0imgs, funimgs = [], []\n",
    "            for offset, img in zip(offsets, data):\n",
    "                if int(offset[0]) == 25527: # offset at far end is regarded as m0\n",
    "                    img = abs(ifft2c(img))\n",
    "                    m0imgs.append(img)\n",
    "                else:\n",
    "                    funimgs.append(img)\n",
    "            self.data_dict[name]['m0'] = torch.mean(torch.stack(m0imgs), 0, keepdim=True)\n",
    "            self.data_dict[name]['fun'] = torch.stack(funimgs)\n",
    "        # contruct nufft object\n",
    "        self.nufft = tkbn.KbNufft(im_size).cuda()\n",
    "        self.adj = tkbn.KbNufftAdjoint(im_size).cuda()\n",
    "        self.dcf = tkbn.calc_density_compensation_function(self.ktrajs, im_size).cuda()\n",
    "    def __len__(self):\n",
    "        count = 0\n",
    "        for key in self.data_dict.keys():\n",
    "            count += len(self.data_dict[key]['fun']) - self.nimgs + 1\n",
    "        return count\n",
    "    def __getitem__(self, index):\n",
    "        # index corresponds which sample\n",
    "        for key in self.data_dict.keys():\n",
    "            nseq = len(self.data_dict[key]['fun']) - self.nimgs + 1\n",
    "            if index - nseq < 0:\n",
    "                break\n",
    "            index -= nseq\n",
    "        # fetch data\n",
    "        m0 = self.data_dict[key]['m0']\n",
    "        kf = self.data_dict[key]['fun'][index:index+self.nimgs].cuda()\n",
    "        # in fft2/ifft2, last two dimensions are the default to be transformed\n",
    "        xf = ifft2c(kf).unsqueeze(1)\n",
    "        ku = self.nufft(xf, self.ktrajs)\n",
    "        zf = self.adj(ku*self.dcf, self.ktrajs)\n",
    "        # normalize\n",
    "        zf, xf = abs(zf).squeeze(), abs(xf).squeeze()\n",
    "        xf = xf / (m0.max() - m0.min())\n",
    "        zf = zf / (zf.max() - zf.min())\n",
    "        m0 = (m0 - m0.min()) / (m0.max() - m0.min())\n",
    "        return zf.to(torch.float32), xf.to(torch.float32), m0.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T17:15:09.437132Z",
     "iopub.status.busy": "2023-11-15T17:15:09.437066Z",
     "iopub.status.idle": "2023-11-15T17:15:09.444099Z",
     "shell.execute_reply": "2023-11-15T17:15:09.443933Z"
    }
   },
   "outputs": [],
   "source": [
    "# transformer with data consistency\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import cat\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, dim_head=64, heads=8):\n",
    "        super().__init__()\n",
    "        self.num_heads = heads\n",
    "        self.dim_head = dim_head\n",
    "        self.to_q = nn.Linear(dim, dim_head * heads, bias=False)\n",
    "        self.to_k = nn.Linear(dim, dim_head * heads, bias=False)\n",
    "        self.to_v = nn.Linear(dim, dim_head * heads, bias=False)\n",
    "        self.rescale = nn.Parameter(torch.ones(heads, 1, 1))\n",
    "        self.proj = nn.Linear(dim_head * heads, dim, bias=True)\n",
    "        self.pos_emb = nn.Conv2d(dim, dim, 3, 1, 1, bias=False, groups=dim)\n",
    "        self.dim = dim\n",
    "    def forward(self, x_in):\n",
    "        b, c, h, w = x_in.shape\n",
    "        x = x_in.permute(0, 2, 3, 1).reshape(b,h*w,c)\n",
    "        # b, hw, hd\n",
    "        q_inp = self.to_q(x)\n",
    "        k_inp = self.to_k(x)\n",
    "        v_inp = self.to_v(x)\n",
    "        # b, h, hw, d\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=self.num_heads), (q_inp, k_inp, v_inp))\n",
    "        # b, h, d, hw\n",
    "        q = q.transpose(-2, -1)\n",
    "        k = k.transpose(-2, -1)\n",
    "        v = v.transpose(-2, -1)\n",
    "        q = F.normalize(q, dim=-1, p=2)\n",
    "        k = F.normalize(k, dim=-1, p=2)\n",
    "        # attn: b, h, d, d\n",
    "        attn = (k @ q.transpose(-2, -1))\n",
    "        attn = attn * self.rescale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        # x: b, h, d, hw\n",
    "        x = attn @ v\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = x.reshape(b, h * w, self.num_heads * self.dim_head)\n",
    "        # out: b, c, h, w\n",
    "        out_c = self.proj(x).view(b, h, w, c).permute(0, 3, 1, 2)\n",
    "        out_p = self.pos_emb(x_in)\n",
    "        out = out_c + out_p\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, mult=4):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(dim, dim * mult, 1, 1, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(dim * mult, dim * mult, 3, 1, 1, bias=False, groups=dim * mult),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(dim * mult, dim, 1, 1, bias=False),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, dim_head=64, heads=8, num_blocks=2):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([])\n",
    "        for _ in range(num_blocks):\n",
    "            self.blocks.append(\n",
    "                nn.ModuleList([\n",
    "                    Attention(dim=dim, dim_head=dim_head, heads=heads),\n",
    "                    FeedForward(dim=dim)\n",
    "                ])\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        for (attn, ff) in self.blocks:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "        return x\n",
    "\n",
    "class MoTR(nn.Module):\n",
    "    def __init__(self, nimgs, dim=16, stages=2, num_blocks=[2,2]):\n",
    "        super(MoTR, self).__init__()\n",
    "        self.nimgs = nimgs\n",
    "        dim_stage, dim_in = dim, 1+nimgs\n",
    "        self.stages = nn.ModuleList()\n",
    "        # embedding - transformer - mapping\n",
    "        for i in range(stages):\n",
    "            self.stages.append(\n",
    "                nn.Sequential(OrderedDict([\n",
    "                    ('embedding', nn.Sequential(nn.Conv2d(dim_in, dim_stage, 3, 1, 1, bias=False), nn.GELU())),\n",
    "                    ('transformer', Transformer(dim_stage, dim, dim_stage//dim, num_blocks[i])),\n",
    "                    ('mapping', nn.Sequential(nn.Conv2d(dim_stage, dim_stage*2, 3, 1, 1, bias=False), nn.GELU()))\n",
    "                ]))\n",
    "            )\n",
    "            dim_stage *= 2\n",
    "            dim_in = dim_stage\n",
    "        # output\n",
    "        self.convout = nn.Conv2d(dim_stage, nimgs, 1)\n",
    "    def forward(self, zf, m0, k0):\n",
    "        x = cat([m0, zf], 1)\n",
    "        for layer in self.stages:\n",
    "            x = layer(x)\n",
    "        xr = self.convout(x)\n",
    "        masks = k0 == 0\n",
    "        kr = fft2c(xr) * masks + k0\n",
    "        xr = abs(ifft2c(kr))\n",
    "        return xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T17:15:09.445490Z",
     "iopub.status.busy": "2023-11-15T17:15:09.445388Z",
     "iopub.status.idle": "2023-11-15T23:09:12.474119Z",
     "shell.execute_reply": "2023-11-15T23:09:12.473881Z"
    }
   },
   "outputs": [],
   "source": [
    "# construct training dataloader and execute training loop\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "nimgs = 8\n",
    "trainset = dataset('data/processed/trains', ktrajs=ktrajs, im_size=[64, 64], nimgs=nimgs)\n",
    "trainloader = DataLoader(trainset, batch_size=8, shuffle=True, drop_last=True)  # shuffle permutes the indices of all samples through torch.randperm(n)\n",
    "\n",
    "# take a snapshot of zf, xf, and m0\n",
    "import matplotlib.pyplot as plt\n",
    "zf, xf, m0 = trainset.__getitem__(nimgs)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(zf[0].cpu().numpy())\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(xf[0].cpu().numpy())\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(m0[0].cpu().numpy())\n",
    "plt.show()\n",
    "\n",
    "# hyper-parameters\n",
    "lr, weight_decay, epochs = 1e-4, 1e-4, 120\n",
    "\n",
    "net = MoTR(nimgs=nimgs, dim=16, stages=3, num_blocks=[3, 2, 1]).cuda()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.99)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "iter = 0\n",
    "writer = SummaryWriter()\n",
    "for epoch in range(epochs):\n",
    "    for zf, xf, m0 in trainloader:\n",
    "        zf, xf, m0 = zf.cuda(), xf.cuda(), m0.cuda()\n",
    "        # forward, you can always trust k0 since it's directly from scanner\n",
    "        k0 = fft2c(xf) * masks.to(xf)\n",
    "        xr = net(zf, m0, k0)\n",
    "        loss = criterion(xr, xf)\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # log\n",
    "        writer.add_scalar('Loss/train', loss.item(), iter)\n",
    "        iter = iter + 1\n",
    "    scheduler.step()\n",
    "\n",
    "torch.save(net.state_dict(), 'variables/motr.pth')\n",
    "\n",
    "# take a snapshot of xr and xf\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(xr[0, 4].detach().cpu().numpy())\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(xf[0, 4].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T23:09:12.475029Z",
     "iopub.status.busy": "2023-11-15T23:09:12.474925Z",
     "iopub.status.idle": "2023-11-15T23:09:57.342734Z",
     "shell.execute_reply": "2023-11-15T23:09:57.342570Z"
    }
   },
   "outputs": [],
   "source": [
    "# construct validation dataloader and execute validation loop\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "nimgs = 8\n",
    "validset = dataset('data/processed/valids', ktrajs=ktrajs, im_size=[64, 64], nimgs=nimgs)\n",
    "validloader = DataLoader(validset, batch_size=1, shuffle=False, drop_last=False)\n",
    "\n",
    "net = MoTR(nimgs=nimgs, dim=16, stages=3, num_blocks=[3, 2, 1]).cuda()\n",
    "net.load_state_dict(torch.load('variables/motr.pth'))\n",
    "\n",
    "net.eval()\n",
    "net.requires_grad_(False)\n",
    "\n",
    "SSIMs, MAEs = [], []\n",
    "for zf, xf, m0 in validloader:\n",
    "    zf, xf, m0 = zf.cuda(), xf.cuda(), m0.cuda()\n",
    "    k0 = fft2c(xf) * masks.to(xf)\n",
    "    xr = net(zf, m0, k0)\n",
    "    xr, xf = xr[0, 4].cpu().numpy(), xf[0, 4].cpu().numpy()\n",
    "    SSIMs.append(ssim(xr, xf, data_range=1.))\n",
    "    MAEs.append(abs(xr-xf).mean())\n",
    "print(f'average ssim of all slices: {np.array(SSIMs).mean()}')\n",
    "print(f'average mae of all slices: {np.array(MAEs).mean()}')\n",
    "\n",
    "# take a snapshot of reconstruction results\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(xr, cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(xf, cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(abs(xr-xf))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
